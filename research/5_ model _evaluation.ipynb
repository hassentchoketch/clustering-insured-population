{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d37474cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a69558aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\tchok\\\\OneDrive\\\\Bureau\\\\My_github\\\\clustering-insured-population\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5393e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806df4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\tchok\\\\OneDrive\\\\Bureau\\\\My_github\\\\clustering-insured-population'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e35724b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class ModelEvaluationConfig:\n",
    "    \"\"\"\n",
    "    Class to hold the evaluation results of a model.\n",
    "    \"\"\"\n",
    "    root_dir: Path\n",
    "    transformed_data_path: Path\n",
    "    model_path: Path\n",
    "    all_params: dict\n",
    "    metric_file_name: Path\n",
    "    visualisation_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4615225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from insuredSegmenter.constants import *\n",
    "from insuredSegmenter.utils.common import read_yaml, create_directories, save_json\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(str(config_filepath))\n",
    "        self.params = read_yaml(str(params_filepath))\n",
    "\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "        params = self.params.kmeans\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            transformed_data_path= self.config.data_transformation.transformed_data_path,\n",
    "            model_path = config.model_path,\n",
    "            all_params=params,\n",
    "            metric_file_name = config.model_evaluation_metric_path,\n",
    "            visualisation_path=config.model_evaluation_plot_path\n",
    "            \n",
    "           \n",
    "        )\n",
    "\n",
    "        return model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29035ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from typing import Dict, Tuple, Any\n",
    "import json\n",
    "\n",
    "def save_json(path: Path, data: Dict):\n",
    "    \"\"\"Save data as JSON file\"\"\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "class ModelEvaluation:\n",
    "    def __init__(self, config: Any):\n",
    "        self.config = config\n",
    "\n",
    "    def eval_metrics(self, X: np.ndarray, labels: np.ndarray) -> Tuple[float, float, float]:\n",
    "        \"\"\"\n",
    "        Calculate clustering evaluation metrics\n",
    "        \n",
    "        Args:\n",
    "            X: Feature matrix\n",
    "            labels: Cluster labels assigned by the model\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (silhouette_score, calinski_harabasz_score, davies_bouldin_score)\n",
    "        \"\"\"\n",
    "        # Note: All these metrics require both the data points and their assigned clusters\n",
    "        s_s = silhouette_score(X, labels)\n",
    "        cal_s = calinski_harabasz_score(X, labels)\n",
    "        dav_s = davies_bouldin_score(X, labels)\n",
    "        return s_s, cal_s, dav_s\n",
    "    # Dict[str, List[float]]\n",
    "    def evaluate_cluster_stability(self, model, X: np.ndarray, n_splits: int = 5):\n",
    "        \"\"\"\n",
    "        Evaluate cluster stability across multiple data subsets\n",
    "        \n",
    "        Args:\n",
    "            model: Trained clustering model\n",
    "            X: Feature matrix of transformed data\n",
    "            n_splits: Number of random splits to evaluate\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with lists of metrics across splits\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            \"silhouette_scores\": [],\n",
    "            \"calinski_harabasz_scores\": [],\n",
    "            \"davies_bouldin_scores\": []\n",
    "        }\n",
    "        \n",
    "        for i in range(n_splits):\n",
    "            # Create a random subset (70% of data)\n",
    "            _, X_subset = train_test_split(X, test_size=0.7, random_state=i)\n",
    "            \n",
    "            # Predict on this subset\n",
    "            labels = model.predict(X_subset)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            s_s, cal_s, dav_s = self.eval_metrics(X_subset, labels)\n",
    "            \n",
    "            # Store results\n",
    "            results[\"silhouette_scores\"].append(s_s)\n",
    "            results[\"calinski_harabasz_scores\"].append(cal_s)\n",
    "            results[\"davies_bouldin_scores\"].append(dav_s)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def visualize_clusters(self, X: np.ndarray, labels: np.ndarray, save_path: Path = None):\n",
    "        \"\"\"\n",
    "        Visualize clusters using PCA for dimensionality reduction\n",
    "        \n",
    "        Args:\n",
    "            X: Feature matrix\n",
    "            labels: Cluster labels assigned by the model\n",
    "            save_path: Path to save the visualization\n",
    "        \"\"\"\n",
    "        # Use PCA to reduce to 2 dimensions for visualization\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X)\n",
    "        \n",
    "        # Create a DataFrame for easy plotting\n",
    "        df_plot = pd.DataFrame({\n",
    "            'PCA1': X_pca[:, 0],\n",
    "            'PCA2': X_pca[:, 1],\n",
    "            'Cluster': labels\n",
    "        })\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=df_plot, palette='viridis')\n",
    "        plt.title('Cluster Visualization using PCA')\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def train_test_evaluation(self) -> Dict:\n",
    "        \"\"\"\"\n",
    "        Perform train/test evaluation of clustering using transformed data\n",
    "        \n",
    "        Args:\n",
    "            model_path: Optional path to load model (uses self.config.model_path if None)\n",
    "            transformed_data_path: Optional path to transformed data (uses self.config.transformed_data_path if None)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with evaluation metrics\n",
    "        \"\"\"\n",
    "        # Load the trained model\n",
    "        # if model_path is None:\n",
    "        #     model_path = self.config.model_path\n",
    "        model = joblib.load(self.config.model_path)\n",
    "        \n",
    "        # Load transformed data\n",
    "        transformed_data = joblib.load(self.config.transformed_data_path)\n",
    "        \n",
    "        # Split into train and test sets\n",
    "        X_train, X_test = train_test_split(transformed_data, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Get cluster assignments for both sets\n",
    "        train_labels = model.predict(X_train)\n",
    "        test_labels = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics for both sets\n",
    "        train_metrics = self.eval_metrics(X_train, train_labels)\n",
    "        test_metrics = self.eval_metrics(X_test, test_labels)\n",
    "        \n",
    "        # Evaluate cluster stability\n",
    "        stability_metrics = self.evaluate_cluster_stability(model, transformed_data)\n",
    "        \n",
    "        # Format results\n",
    "        results = {\n",
    "            \"train_metrics\": {\n",
    "                \"silhouette_score\": train_metrics[0],\n",
    "                \"calinski_harabasz_score\": train_metrics[1],\n",
    "                \"davies_bouldin_score\": train_metrics[2]\n",
    "            },\n",
    "            \"test_metrics\": {\n",
    "                \"silhouette_score\": test_metrics[0],\n",
    "                \"calinski_harabasz_score\": test_metrics[1],\n",
    "                \"davies_bouldin_score\": test_metrics[2]\n",
    "            },\n",
    "            \"stability_metrics\": {\n",
    "                \"silhouette_scores_mean\": np.mean(stability_metrics[\"silhouette_scores\"]),\n",
    "                \"silhouette_scores_std\": np.std(stability_metrics[\"silhouette_scores\"]),\n",
    "                \"calinski_harabasz_scores_mean\": np.mean(stability_metrics[\"calinski_harabasz_scores\"]),\n",
    "                \"calinski_harabasz_scores_std\": np.std(stability_metrics[\"calinski_harabasz_scores\"]),\n",
    "                \"davies_bouldin_scores_mean\": np.mean(stability_metrics[\"davies_bouldin_scores\"]),\n",
    "                \"davies_bouldin_scores_std\": np.std(stability_metrics[\"davies_bouldin_scores\"])\n",
    "            },\n",
    "            \"interpretation\": {\n",
    "                \"silhouette_score\": \"Values near 1 indicate well-defined clusters. Values near 0 indicate overlapping clusters.\",\n",
    "                \"calinski_harabasz_score\": \"Higher values indicate better-defined clusters.\",\n",
    "                \"davies_bouldin_score\": \"Lower values indicate better clustering.\",\n",
    "                \"stability\": \"Lower standard deviation values indicate more stable clustering across different data subsets.\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def save_results(self):\n",
    "        \"\"\"\n",
    "        Load the model, evaluate it on transformed data, and save metrics\n",
    "        \n",
    "        In clustering, we should always evaluate using the same transformed data\n",
    "        that was used during model training. Otherwise, the clusters won't align\n",
    "        properly with the evaluation data.\n",
    "        \"\"\"\n",
    "        # Load the trained model\n",
    "        model = joblib.load(self.config.model_path)\n",
    "        \n",
    "        # Load transformed data from pickle file\n",
    "        # For clustering evaluation, we must use the same transformation as training\n",
    "        transformed_data = joblib.load(self.config.transformed_data_path)\n",
    "        \n",
    "        # Use the train_test_evaluation method with transformed data\n",
    "        results = self.train_test_evaluation()\n",
    "        \n",
    "        # Save metrics\n",
    "        save_json(path=Path(self.config.metric_file_name), data=results)\n",
    "        \n",
    "        # # Optionally visualize the clusters using transformed data\n",
    "        # if hasattr(self.config, 'model_evaluation_plot_path'):\n",
    "            # For visualization, use all transformed data\n",
    "        all_labels = model.predict(transformed_data)\n",
    "        self.visualize_clusters(transformed_data, all_labels, save_path=Path(self.config.model_evaluation_plot_path))\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b5c8ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-15 15:36:20,540: INFO: common: YAML file loaded successfully: C:\\Users\\tchok\\OneDrive\\Bureau\\My_github\\clustering-insured-population\\config\\config.yaml]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-15 15:36:20,560: INFO: common: YAML file loaded successfully: C:\\Users\\tchok\\OneDrive\\Bureau\\My_github\\clustering-insured-population\\params.yaml]\n",
      "[2025-05-15 15:36:20,588: INFO: common: created directory at: artifacts]\n",
      "[2025-05-15 15:36:20,592: INFO: common: created directory at: artifacts/model_evaluation]\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    config = ConfigurationManager()\n",
    "    evaluation_config = config.get_model_evaluation_config()\n",
    "    evaluation_instance = ModelEvaluation(config=evaluation_config)\n",
    "    evaluation_instance.save_results()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
